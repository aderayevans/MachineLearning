{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add14cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, predict_data, parent, left_child, right_child, \n",
    "                     label, mean, mse, samples, value, level, leaf=False):\n",
    "        self.predict_data = predict_data\n",
    "        self.parent = parent\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.label = label\n",
    "        self.mean = mean\n",
    "        self.mse = mse\n",
    "        self.samples = samples\n",
    "        self.value = value\n",
    "        self.level = level\n",
    "        self.leaf = leaf\n",
    "    def display(self):\n",
    "        for i in range (0, self.level):\n",
    "            print('|   ', end = '')\n",
    "        print('|--- ', end = '')\n",
    "        if self.leaf == False:\n",
    "            print(self.label, '<=', self.mean)\n",
    "        else:\n",
    "            print('value: [', self.value, ']', sep='')\n",
    "        if self.left_child != None:\n",
    "            self.left_child.display()\n",
    "        if self.right_child != None:\n",
    "            for i in range (0, self.level):\n",
    "                print('|   ', end = '')\n",
    "            print('|--- ', end = '')\n",
    "            print(self.label, '>', self.mean)\n",
    "            self.right_child.display()\n",
    "    \n",
    "    def _display(self):\n",
    "        for i in range (0, self.level):\n",
    "            print('|   ', end = '')\n",
    "        print('|--- ', end = '')\n",
    "        if self.leaf == False:\n",
    "            print(self.label, '<=', self.mean, end = ', ')\n",
    "            print('mse =', self.mse, end = ', ')\n",
    "            print('samples =', self.samples, end = ', ')\n",
    "            print('value =', self.value)\n",
    "        else:\n",
    "            print('value: [', self.value, ']', sep='')\n",
    "        if self.left_child != None:\n",
    "            self.left_child.display()\n",
    "        if self.right_child != None:\n",
    "            for i in range (0, self.level):\n",
    "                print('|   ', end = '')\n",
    "            print('|--- ', end = '')\n",
    "            print(self.label, '>', self.mean, end = ', ')\n",
    "            print('mse =', self.mse, end = ', ')\n",
    "            print('samples =', self.samples, end = ', ')\n",
    "            print('value =', self.value)\n",
    "            self.right_child.display()\n",
    "    \n",
    "    def set_left_child(self, left_child):\n",
    "        self.left_child = left_child\n",
    "    \n",
    "    def set_right_child(self, right_child):\n",
    "        self.right_child = right_child\n",
    "    \n",
    "    def predict(self, x_test_instance_dict):\n",
    "        if self.left_child != None and x_test_instance_dict[self.label] <= self.mean:\n",
    "            return self.left_child.predict(x_test_instance_dict)\n",
    "        elif self.right_child != None and x_test_instance_dict[self.label] > self.mean:\n",
    "            return self.right_child.predict(x_test_instance_dict)\n",
    "        else: #is a leaf\n",
    "            #print('$$$', self.predict_data.values.tolist()[0])\n",
    "            #self.parent.display()\n",
    "            return self.predict_data.value_counts().index[0]\n",
    "    \n",
    "    def getKey(self):\n",
    "        return str(self.label) + ' <= ' + str(self.mean)\n",
    "    \n",
    "    def getValue(self):\n",
    "        if self.leaf:\n",
    "            return self.predict_data.value_counts().index[0]\n",
    "        else:\n",
    "            return {self.getKey(): [self.left_child.getValue(), self.right_child.getValue()]}\n",
    "    \n",
    "    def isLeaf(self):\n",
    "        return self.leaf\n",
    "    \n",
    "    def be_leaf(self): #turn to a leaf\n",
    "        this_node = copy.copy(self)\n",
    "        left_node = None\n",
    "        right_node = None\n",
    "        this_node.set_left_child(left_node)\n",
    "        this_node.set_right_child(right_node)\n",
    "        this_node.leaf = True\n",
    "        return this_node\n",
    "    \n",
    "    def prune_by_level(self, max_depth):\n",
    "        if self.leaf:\n",
    "            return copy.copy(self)\n",
    "        elif self.level == max_depth:\n",
    "            return self.be_leaf()\n",
    "        else:\n",
    "            this_node = copy.copy(self)\n",
    "            left_node = this_node.left_child.prune_by_level(max_depth)\n",
    "            right_node = this_node.right_child.prune_by_level(max_depth)\n",
    "            this_node.set_left_child(left_node)\n",
    "            this_node.set_right_child(right_node)\n",
    "            return this_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ad609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth = 0):\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self.max_depth = 0\n",
    "        self.tree = None\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.dict_tree = None\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.data = x_train\n",
    "        self.target = y_train\n",
    "        self.tree = self.build_tree(self.data, self.target, 0, None)\n",
    "        self.dict_tree = self.build_dict(self.tree)\n",
    "    \n",
    "    def best_split(self, df, label, best_mse):\n",
    "        print(df)\n",
    "        #use to save best feature and its value easily\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        \n",
    "        #use to drop features got only one unique\n",
    "        drop_data_columns = []\n",
    "        for feature in df.columns:\n",
    "            df = df.dropna().sort_values(feature)\n",
    "            if feature == label: continue\n",
    "            if len(np.unique(df[feature])) == 1:\n",
    "                drop_data_columns.append(feature)\n",
    "                continue\n",
    "            ### calculate moving average (MA), to split into left and right branch\n",
    "            means = np.convolve(df[feature].unique(), np.ones(2), 'valid') / 2\n",
    "            print(means)\n",
    "            for val in means:\n",
    "                left_y = df[df[feature] <= val]['Y'].values\n",
    "                right_y = df[df[feature] > val]['Y'].values\n",
    "                left_mean = np.mean(left_y)\n",
    "                right_mean = np.mean(right_y)\n",
    "                # Getting the left and right residuals \n",
    "                res_left = left_y - left_mean \n",
    "                res_right = right_y - right_mean\n",
    "                # Concatenating the residuals \n",
    "                residuals = np.concatenate((res_left, res_right), axis=None)\n",
    "                # Calculate mse when we split with this MA of this FEATURE\n",
    "                mse_split = np.sum(residuals ** 2) / len(residuals)\n",
    "                print(feature, val, mse_split)\n",
    "                # Compare mse, take min\n",
    "                if mse_split < best_mse:\n",
    "                    best_feature = feature\n",
    "                    best_value = val\n",
    "                    best_mse = mse_split\n",
    "                    print('*****')\n",
    "        #print(best_feature)\n",
    "        #print(best_value)\n",
    "        #print(best_mse)\n",
    "        #drop no need feature\n",
    "        for feature in drop_data_columns:\n",
    "            df = df.drop(columns = [feature])\n",
    "        return df, best_feature, best_value\n",
    "    \n",
    "    def build_tree(self, data, target, level, parent):\n",
    "        df = data.copy()\n",
    "        df['Y'] = target\n",
    "        \n",
    "        #Calculate mse_base\n",
    "        temp_y = (df['Y'] - np.mean(df['Y'])) ** 2\n",
    "        mse_base = np.sum(temp_y) / len(df['Y'])\n",
    "        \n",
    "        #save value for node (just ignore these till create Node\n",
    "        value = np.mean(df['Y'])\n",
    "        samples = len(df['Y'])\n",
    "        if len(df['Y'].unique()) == 1 or (self.max_depth != 0 and level >= self.max_depth):\n",
    "            print('Making leaf:', round(mse_base, 3), samples, round(value, 3), len(df['Y'].unique()))\n",
    "            print('###')\n",
    "            print(df['Y'])\n",
    "            print('###')\n",
    "            return Node(df['Y'], parent, None, None, None, None, round(mse_base, 3), samples, round(value, 3), level, True)\n",
    "        \n",
    "        #'best' spliter    \n",
    "        df, best_feature, best_value = self.best_split(df, 'Y', mse_base)\n",
    "        if best_feature == None: return None\n",
    "        else: self.depth = max(self.depth, level)\n",
    "        subset_left = df[df[best_feature] <= best_value]\n",
    "        subset_right = df[df[best_feature] > best_value]\n",
    "        left_Node = None\n",
    "        right_Node = None\n",
    "        newNode = Node(df['Y'],\n",
    "                        parent, left_Node, right_Node, \n",
    "                        best_feature, \n",
    "                        round(best_value, 3), \n",
    "                        round(mse_base, 3), \n",
    "                        samples, \n",
    "                        round(value, 3),\n",
    "                        level\n",
    "                       )\n",
    "        #newNode.display()  \n",
    "        left_Node = self.build_tree(subset_left, subset_left['Y'], level+1, newNode)\n",
    "        right_Node = self.build_tree(subset_right, subset_right['Y'], level+1, newNode)\n",
    "        newNode.set_left_child(left_Node)\n",
    "        newNode.set_right_child(right_Node)\n",
    "        return newNode\n",
    "    \n",
    "    def display(self):\n",
    "        self.tree.display()\n",
    "    \n",
    "    def build_dict(self, tree):\n",
    "        ##build tree dictionary\n",
    "        dict_tree = {tree.getKey() : [tree.left_child.getValue(), tree.right_child.getValue()]}\n",
    "        return dict_tree\n",
    "    \n",
    "    def get_tree(self, max_depth=0):\n",
    "        if max_depth == 0 or max_depth == self.depth:\n",
    "            return self.tree, self.dict_tree\n",
    "        else:\n",
    "            pruned_tree = copy.copy(self.tree)\n",
    "            pruned_tree = pruned_tree.prune_by_level(max_depth)\n",
    "            dict_tree = self.build_dict(pruned_tree)\n",
    "            return pruned_tree, dict_tree\n",
    "    \n",
    "    def get_dict_tree(self):\n",
    "        return self.dict_tree\n",
    "    \n",
    "    def predict_tree(tree, df_test):\n",
    "        y_pred = df_test.apply(tree.predict, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, x_test, tree=None):\n",
    "        if tree == None:\n",
    "            tree = self.tree\n",
    "        y_pred = x_test.apply(tree.predict, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def prune(self, df_val, label, ml_task='classification'):\n",
    "        df_train = self.data.copy()\n",
    "        df_train[label] = self.target\n",
    "        \n",
    "        self.tree = self.post_pruning(df_train, df_val, label, tree=None, ml_task=ml_task)\n",
    "    \n",
    "    def determine_leaf(self, label, ml_task='classification'):\n",
    "        df_train = self.data.copy()\n",
    "        df_train[label] = self.target\n",
    "        \n",
    "        if ml_task == 'regression':\n",
    "            return df_train[label].mean()\n",
    "        else:\n",
    "            #take the most numberous leaf\n",
    "            return df_train[label].value_counts().index[0]\n",
    "    \n",
    "    def determine_errors(self, label, df_val, tree, ml_task='classification'):\n",
    "        actual_values = df_val[label]\n",
    "        predictions = self.predict(df_val, tree)\n",
    "        \n",
    "        if ml_task == 'regression':\n",
    "            #mse\n",
    "            return ((actual_values - predictions) ** 2).mean()\n",
    "        else:\n",
    "            return sum(actual_values != predictions)\n",
    "    \n",
    "    def post_pruning(self, df_train, df_val, label, tree=None, ml_task='classification'):\n",
    "        if tree == None:\n",
    "            tree = self.tree\n",
    "        pruned_tree = copy.copy(tree)\n",
    "\n",
    "        yes_answer = pruned_tree.left_child\n",
    "        no_answer = pruned_tree.right_child\n",
    "\n",
    "        #its child right below is leaf\n",
    "        if yes_answer.isLeaf() and no_answer.isLeaf():\n",
    "            leaf = self.determine_leaf(label, ml_task=ml_task)\n",
    "            \n",
    "            errors_leaf = self.determine_errors(label, df_val, pruned_tree.be_leaf(), ml_task=ml_task)\n",
    "            errors_decision_node = self.determine_errors(label, df_val, pruned_tree, ml_task=ml_task)\n",
    "            if errors_leaf <= errors_decision_node:\n",
    "                print('^^^^')\n",
    "                pruned_tree.display()\n",
    "                print('pruning . . .')\n",
    "                pruned_tree.be_leaf().display()\n",
    "                print('~~~~')\n",
    "                return pruned_tree.be_leaf()\n",
    "            else: \n",
    "                return pruned_tree\n",
    "        else:\n",
    "            feature = pruned_tree.label\n",
    "            value = pruned_tree.mean\n",
    "            df_train_yes = df_train[df_train[feature] <= value]\n",
    "            df_train_no = df_train[df_train[feature] > value]\n",
    "            df_val_yes = df_val[df_val[feature] <= value]\n",
    "            df_val_no = df_val[df_val[feature] > value]\n",
    "            if len(df_train_yes) == 0 or len(df_train_no) == 0 or len(df_val_yes) == 0 or len(df_val_no) == 0:\n",
    "                    return pruned_tree\n",
    "            \n",
    "            if not yes_answer.isLeaf():\n",
    "                yes_answer = self.post_pruning(df_train_yes, df_val_yes, label, yes_answer)\n",
    "                pruned_tree.set_left_child(yes_answer)\n",
    "            if not no_answer.isLeaf():\n",
    "                no_answer = self.post_pruning(df_train_no, df_val_no, label, no_answer)\n",
    "                pruned_tree.set_right_child(no_answer)\n",
    "            return pruned_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3de7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name, label, opt=2):\n",
    "    if opt == 0: #create normalized_data\n",
    "        dt = pd.read_csv('SeoulBikeData.csv')\n",
    "        dt, normalize_ar = normalize(dt, label)\n",
    "        #print(normalize_ar)\n",
    "        with open('attribute_convert_map.txt', 'w', encoding='utf-8') as f:\n",
    "            for item in normalize_ar:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        writeCsv(dt, 'normalized_data.csv')\n",
    "        writeCsv(dt.iloc[0:10], 'test.csv')\n",
    "    elif opt == 1:\n",
    "        dt = pd.read_csv('test.csv', index_col = 0)\n",
    "    else: #read test_data\n",
    "        dt = pd.read_csv('normalized_data.csv', index_col = 0)\n",
    "        #dt.columns = dt.columns.str.replace(r'[^A-Za-z0-9]', '', regex=True)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_object_to_file(the_object, file_name):\n",
    "    with open(file_name, 'wb') as output:\n",
    "        pickle.dump(the_object, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object_from_file(file_name):\n",
    "    with open(file_name, 'rb') as input:\n",
    "        the_object = pickle.load(input)\n",
    "    return the_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCsv(dataframe, filename):\n",
    "    dataframe.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(x_train, y_train, x_test, y_test, x_valid, y_valid, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('mse =', mse)\n",
    "    rmse_err = np.sqrt(mse)\n",
    "    print('root mse =', rmse_err)\n",
    "    for each in x_test.columns:\n",
    "        plt.scatter(x_train[each], y_train, color='blue')\n",
    "        #plt.scatter(x_test[each], y_test, color='red')\n",
    "        #plt.scatter(x_valid[each], y_valid, color='violet')\n",
    "        #plt.scatter(x_test[each], y_pred, color='green')\n",
    "        plt.xlabel(each)\n",
    "        plt.ylabel(y_test.name)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d66ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions_lines(dr, x_test, y_test):\n",
    "    df_test = x_test.copy()\n",
    "    df_test[y_test.name] = y_test\n",
    "    df_test.apply(create_plot, args=(dr, df_test, y_test.name), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d939aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dt, label):\n",
    "    attribute_list = dt.columns\n",
    "    return_list = []\n",
    "    for attribute in attribute_list:\n",
    "        if attribute == label:\n",
    "            continue\n",
    "        array = np.unique(dt[attribute])\n",
    "        list_ = array.tolist()\n",
    "        if isinstance(array[0], str):\n",
    "            #for index in list_:\n",
    "            #    dt[attribute] = dt[attribute].replace({index: list_.index(index)})\n",
    "            min = 0\n",
    "            max = (len(list_) - 1)\n",
    "            ##interval = max - min\n",
    "            for index in list_:\n",
    "                #return_list.append({attribute:{index: ((list_.index(index) - min)/(max - min))}})\n",
    "                #dt[attribute] = dt[attribute].replace({index: ((list_.index(index) - min)/(max - min))}) \n",
    "                return_list.append({attribute:{index: list_.index(index)}})\n",
    "                dt[attribute] = dt[attribute].replace({index: list_.index(index)}) \n",
    "                \n",
    "        #else:\n",
    "        #    min = np.amin(array)\n",
    "        #    max = np.amax(array)\n",
    "        #    ##interval = max - min\n",
    "        #    for index in list_:\n",
    "        #        return_list.append({attribute:{index: ((index - min)/(max - min))}})\n",
    "        #        dt[attribute] = dt[attribute].replace({index: ((index - min)/(max - min))})    \n",
    "    return dt, return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dea032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred) ** 2) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd223e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, label):\n",
    "    x = df.drop(columns = [label])\n",
    "    y = df[label]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=0.3, random_state=10, shuffle=True)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, \n",
    "                                                    test_size=0.5, random_state=10, shuffle=False)\n",
    "    return x_train, y_train, x_test, y_test, x_valid, y_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(the_column, dr, df_test, label):\n",
    "    the_column = the_column.name\n",
    "    if the_column == label: return\n",
    "    x_test = df_test.sort_values(by=the_column)\n",
    "    y_test = df_test[label]\n",
    "            \n",
    "    y_pred = dr.predict(x_test)\n",
    "    \n",
    "    ##\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('mse =', mse)\n",
    "    rmse_err = np.sqrt(mse)\n",
    "    print('root mse =', rmse_err)\n",
    "    ##\n",
    "    #plot_df = pd.DataFrame({'actual':y_test,'predictions':y_pred})\n",
    "    #plt.plot(x_test[the_column], plot_df, color='blue')\n",
    "    \n",
    "    plot_df = pd.DataFrame({'actual':y_test,'predictions':y_pred})\n",
    "    plt.plot(x_test[the_column], plot_df)\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_DecisionTreeRegressor(x_train, y_train, visualize=True):                                           \n",
    "    #print(x_train)\n",
    "    #print(y_train)\n",
    "    \n",
    "    dr = DecisionTreeRegressor(max_depth = 0)\n",
    "    dr.fit(x_train, y_train)\n",
    "    \n",
    "    write_object_to_file(dr, 'trained_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ce398",
   "metadata": {},
   "outputs": [],
   "source": [
    "label='Rented_Bike_Count'\n",
    "df = read_data('SeoulBikeData.csv', label, opt=2)\n",
    "df.columns = df.columns.str.replace(r'[^a-zA-Z0-9]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925261b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_valid, y_valid = split(df, label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1c43823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 174730.9917546303\n",
      "root mse = 418.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lm.predict(x_test)\n",
    "    \n",
    "##mse\n",
    "err = mean_squared_error(y_test, y_pred)\n",
    "print('mse =', err)\n",
    "##root mse = sqrt(mse)\n",
    "rmse_err = np.sqrt(err)\n",
    "print('root mse =', round(rmse_err, 3))\n",
    "    \n",
    "#plt.scatter(x_test.lotsize, y_pred, color='red')\n",
    "#plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31066439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_with_DecisionTreeRegressor(x_train, y_train, visualize=True)\n",
    "\n",
    "dr = read_object_from_file('trained_data.pkl')\n",
    "#dr.display()\n",
    "tree = dr.get_dict_tree()\n",
    "#pprint(dr.get_dict_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff990ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = x_train.copy()\n",
    "df_train[label] = y_train\n",
    "df_val = x_valid.copy()\n",
    "df_val[label] = y_valid\n",
    "\n",
    "ft = dr.tree.label\n",
    "val = dr.tree.value\n",
    "\n",
    "pruned_tree, pruned_dict = dr.get_tree(max_depth=2)\n",
    "pprint(pruned_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions_lines(dr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8211e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.prune(df_val, label, ml_task='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36034007",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions_lines(dr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = x_train.copy()\n",
    "df_train[label] = y_train\n",
    "df_val = x_valid.copy()\n",
    "df_val[label] = y_valid\n",
    "   \n",
    "y_pred = dr.predict(x_test)\n",
    "#print(y_pred)\n",
    "#for val in y_pred:\n",
    "#    print(val)\n",
    "       \n",
    "#show_predictions_lines(dr, x_test, y_test)\n",
    "    \n",
    "#show_plot(x_train, y_train, x_test, y_test, x_valid, y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(x_train, y_train, x_test, y_test, x_valid, y_valid, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
